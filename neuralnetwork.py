# -*- coding: utf-8 -*-
"""Copy of assignmenttwo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZnUNqq8lnTV_2qBd2X1IJmujcxVTm1-Q
"""

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np

data = pd.read_csv("https://raw.githubusercontent.com/pranavn21/real-estate/main/mushroom_csv.csv")

#preprocesing
mappings=list()

encoder=LabelEncoder() # Converts categories into numbers

for column in range(len(data.columns)): # Convert all columns and one-hot encode each category into a new column
    data[data.columns[column]]=encoder.fit_transform(data[data.columns[column]])
    mappings_dict={index:label for index,label in enumerate(encoder.classes_)}
    mappings.append(mappings_dict)
y=data['class']
x=data.drop('class',axis=1)

scaler=StandardScaler() # standard scaling, change to 0-1
x=pd.DataFrame(scaler.fit_transform(x),columns=x.columns)
X_train,X_test,y_train,y_test=train_test_split(x,y,train_size=0.8)

# Do the neural network parameters,run code with different iterations and parameters (below in CLF MLPClassifier call).
# Preprocess/clean data, has to be done after the conversion above. Use dropna command, etc

from sklearn.metrics import accuracy_score
train_score = []
for act in ('logistic', 'tanh', 'relu'):
    for lr in (.01, .1):
        for iter in (100, 200):
            for hiddenl in ((2,), (3,)):
                acc_score = []
                mlp = MLPClassifier(hidden_layer_sizes=hiddenl, activation=act, max_iter=iter, alpha=1e-4,
                                    solver='adam', verbose=10, tol=1e-8, random_state=1,
                                    learning_rate_init=lr)
# Training loop (you can adjust the number of epochs and other hyperparameters)
                n_epochs = iter
                for epoch in range(n_epochs):
                    # Incremental training using partial_fit
                    mlp.partial_fit(X_train, y_train, classes=np.unique(y_train))

                    # Make predictions on the training set
                    y_pred = mlp.predict(X_train)
                    # Calculate the accuracy for the current epoch
                    accuracy = accuracy_score(y_train, y_pred)
                    print(f"Epoch {epoch + 1}, Accuracy: {accuracy:.2f}")
                    acc_score.append(accuracy) # We append the accuracy to a tabular format

                train_score.append(acc_score)
                # print(act, lr, iter, hiddenl) # Print sequence of labels
                print("\n\nParameters: ", lr, act, hiddenl, iter)
                y_pred_test = mlp.predict(X_test)  # Make predictions on the test set
                test_accuracy = accuracy_score(y_test, y_pred_test)
                print(f"Test Accuracy: {test_accuracy:.2f}\n\n")



import matplotlib.pyplot as plt

fig, ax = plt.subplots()
ax.plot(train_score[0], label='0')
ax.plot(train_score[1], label='1')
ax.plot(train_score[2], label='2')
ax.plot(train_score[3], label='3')
ax.plot(train_score[4], label='4')
ax.plot(train_score[5], label='5')
ax.plot(train_score[6], label='6')
ax.plot(train_score[7], label='7')
ax.plot(train_score[8], label='8')
ax.plot(train_score[9], label='9')
ax.plot(train_score[10], label='10')
ax.plot(train_score[11], label='11') # Change labels
ax.plot(train_score[12], label='12')
ax.plot(train_score[13], label='13')
ax.plot(train_score[14], label='14')
ax.plot(train_score[15], label='15')
ax.plot(train_score[16], label='16')
ax.plot(train_score[17], label='17')
ax.plot(train_score[18], label='18')
ax.plot(train_score[19], label='19')
ax.plot(train_score[20], label='20')
ax.plot(train_score[21], label='21')
ax.plot(train_score[22], label='22')
ax.plot(train_score[23], label='23')

legend = ax.legend(loc='best', fontsize='x-large')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Comparison of MLP Training')
plt.show()

x, y = make_classification(n_samples=100, random_state=1)
X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=1)
clf = MLPClassifier(hidden_layer_sizes=(8, 8), max_iter=190, alpha=1e-4,
              solver='sgd', verbose=10, tol=1e-4, random_state=1,
              learning_rate_init=.01)
clf.fit(X_train, y_train)
clf.predict(X_test)
clf.score(X_test, y_test)

#