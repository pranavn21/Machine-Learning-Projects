## Linear Regression using Gradient Descent

### This assignment is a part of my assignments in CS 4375: Machine Learning

---

How to run: This is a python code genertated with Google Colab Python notebooks. Ensure you are in the proper directory if using a terminal and run the following command: python <path_to_file>.py

If you are running via an IDE, then make sure that Python is installed and simply press Run.

# Part 1

This is my self-developed gradient descent algorithm applied to a linear regression problem. I used some libraries to implement this by myself as listed below. I used the Real Estate dataset, which can be found [here](https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set).

The steps I took to develop my algorithm were:

- Choosing a sufficient dataset from the UCI ML Repository
- Pre-processing the dataset (removing null/NA values, removing any redundant rows, converting categorical variables to numerical variables, removing irrelevant variables, etc.)

# Part 2

This is a much simpler code as I used an already-developed ML library from the [Scikit Learn package](https://scikit-learn.org/) to perform linear regression. The purpose of this was to compare the results between Part 1 and Part 2 to find the better algorithm.

# Libraries utilized:

Pandas, Numpy, Matplotlib, Sklearn (sci-kit learn)

---

# References

- [GeeksForGeeks - How to find a local minimum](https://www.geeksforgeeks.org/how-to-implement-a-gradient-descent-in-python-to-find-a-local-minimum/)
- [Wikipedia - Explained variation](https://en.wikipedia.org/wiki/Explained_variation)
